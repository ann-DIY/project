---
title: "Project 2"
author: "SDS348 Fall 2019"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
library(knitr)
opts_chunk$set(fig.align="center", fig.height=5, message=FALSE, warning=FALSE, fig.width=8, tidy.opts=list(width.cutoff=60),tidy=TRUE)

```

## Ann Wang, aw29983

---

#### Introduction:
This is the 'meteorites' dataset, which is a dataset containing information about meteorites and where they fell. This dataset was obtained from the Meteoritical Society by NASA. It contains the variables: name, id, name_type, class, mass, fall, year, lat, long, and geolocation of the meteorites. 


##### MANOVA TESTING

```{R}
library(mvtnorm); library(ggExtra); library(ggplot2);library(dplyr); library(tidyverse); library(lmtest)
#install.packages("glmnet")
library(glmnet)
meteorites <- readr::read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-11/meteorites.csv") %>% na.omit
ggplot(meteorites, aes(x = year, y = mass)) +  geom_point(alpha = .5) + geom_density_2d(h=2) + coord_fixed() + facet_wrap(~fall)
man1<-manova(cbind(year,mass)~fall, data=meteorites)
summary(man1)
summary.aov(man1)

meteorites %>% group_by(fall) %>% summarize(mean(year), mean(mass))
pairwise.t.test(meteorites$year,meteorites$fall, p.adj="none")
pairwise.t.test(meteorites$mass,meteorites$fall, p.adj="none")

1 - (0.95^4) # probability of at least one type I error
0.05/7 #Boneferroni correction
```
The one-way multivariate analysis of variance (MANOVA) was conducted to determine the effect of meteorite type (fell or found) on two variables (year and mass). Based on the MANOVA, there were significant difference found between the two meteorite types, Pillai trace= 0.2588, pseudoF (2,38112)= 6653.7, p <0.0001. Univariate analyses of variance for each variable were conducted as follow-up tests to the MANOVA. The univerate ANOVAs for year was significant with p < 0.0001. The univerate ANOVAs for mass was not significant with p > 0.05. The found and fell groups differ based on year, but not mass. 

I performed 1 MANOVA, 2 ANOVAs, and 4 t tests, so Î± = 0.05/7 as significance level. The probability of at least one type I error, unadjusted, is 0.1854938. The Bonferroni corrected significance level is 0.007142857. The year is still significant, while the mass is not. There are several assumptions including multivariate normality, equal covariance between two dependent variables, linear relationships among variables, no extreme univariate or multivariate outliers, and no multicollinearity. It is likely that not all assumptions are met. 


##### Randomization Test

```{R}
fall_type<-meteorites %>% select(fall, mass)
head(fall_type)
ggplot(fall_type,aes(mass,fill=fall))+geom_histogram(bins=6.5)+facet_wrap(~fall,ncol=2)
fall_type %>% group_by(fall) %>% summarize(means=mean(mass)) %>% summarize(mean_diff=diff(means))

rand_dist<-vector() 
for(i in 1:5000){
  new<-data.frame(mass=sample(fall_type$mass),fall_type=fall_type$fall)
  rand_dist[i]<-mean(new[new$fall_type=="Fell",]$mass)
  mean(new[new$condition=="Found",]$mass)}

{hist(rand_dist, main = "", ylab = ""); abline(v=-32822.54, col="red")}
mean(rand_dist>32822.54)*2 #p-value
```
Null Hypothesis: Mean mass is the same for fall_type (fell vs. found) meteorites.
Alternative Hypothesis: Mean mass is not the same for fall_type (fell vs. found) meteorites.
Based on this test, we fail to reject the null hypothesis (p>0.05). There is a probability of 0.2796 to get a mean difference if the outcome data was split into every possible random grouping. 


##### Linear Regression


```{R}
meteorites$lat_c<-meteorites$lat-mean(meteorites$lat)
meteorites$long_c<-meteorites$long-mean(meteorites$long)

fit1<-lm(mass~lat_c+long_c, data = meteorites)

summary(fit1)
ggplot(meteorites,aes(y=long_c,x=lat_c,color=mass))+geom_point()+stat_smooth(method="lm",se=FALSE)
ggplot(meteorites,aes(y=mass,x=long_c))+geom_point()+stat_smooth(method="lm",se=FALSE)
ggplot(meteorites,aes(y=mass,x=lat_c))+geom_point()+stat_smooth(method="lm",se=FALSE)

qqnorm(meteorites$lat_c)
qqnorm(meteorites$long_c)

shapiro.test(head(meteorites$lat_c))
shapiro.test(head(meteorites$long_c))

bptest(fit1) #testing heteroskedasticity assumption

library(sandwich)
coeftest(fit1, vcov = vcovHC(fit1)) 

summary(fit1)$r.sq

fit5<-lm(mass~lat, data = meteorites) #main effects of lat
summary(fit5)
fit6<-lm(mass~long, data = meteorites) #main effects of long
summary(fit6)

#install.packages("interactions")
library(interactions)
interact_plot(fit1,lat_c,long_c) #interaction plot 

```

For every one unit increase in mass, the latitude increases by 341.81 units and the longitude decreases by 54.17 units. The linearity assumption is violated based on the ggplot. There does seem to be normality based on the q-q plots. From the Shapiro-Wilk, the p-value > 0.05 implying that the distribution of the data are not significantly different from normal distribution. In other words, we can assume the normality. Based on the Breusch-Pagan test, the p-Value < 0.05 indicates that the null hypothesis can not be rejected and therefore heterscedasticity does not exists.  With the robust standard errors, both the t values and the p-values decreased. The proportion of the variation in the outcome explained by this model is 0.0008860555.


##### Regression with Interaction

```{R}
fit2<-lm(mass~lat*long, data = meteorites)
boot_sd<-meteorites[sample(nrow(meteorites),replace=TRUE),]

samp_distn<-replicate(1000, {
  boot_sd<-meteorites[sample(nrow(meteorites),replace=TRUE),]
  fit3<-lm(mass~lat*long,data=boot_sd)
  coef(fit3)
  })

samp_distn%>%t%>%as.data.frame%>%summarize_all(sd)

summary(fit2) #uncorrected SEs
coeftest(fit2, vcov = vcovHC(fit2)) #corrected SEs

```
The p-values for the corrected SEs are higher than the p-values of the uncorrected ones. Additionally the Std. Errors for the corrected SEs are also higher than the uncorrected ones. 

##### Logistic Regression
```{R}
meteorites$y<-ifelse(meteorites$fall=="Found",1,0)
fit3<-glm(y~year+name_type, data = meteorites, family="binomial")
coeftest(fit3)
exp(coef(fit3))

meteorites$prob<-predict(fit3,type="response") #save predicted probabilities
table(predict= as.numeric(meteorites$prob>0.5), truth = meteorites$y) %>% addmargins()

36850/37050 #TPR
313/1065 #TNR
36850/37602 #PPV


pca1<-princomp(meteorites[c('year','mass')])
meteorites$predictor<-pca1$scores[,1]
ggplot(meteorites, aes(predictor,prob))+geom_point(aes(color=fall),alpha=.5,size=3) 
ggplot(meteorites)+geom_density(aes(prob,fill=y))+xlab("logit")# plot density of log-odds (logit) by your binary outcome variable

sens<-function(p,data=meteorites, y=y) mean(meteorites[meteorites$y==1,]$prob>p)
spec<-function(p,data=meteorites, y=y) mean(meteorites[meteorites$y==0,]$prob<p)

sensitivity<-sapply(seq(0,1,.01),sens,meteorites)
specificity<-sapply(seq(0,1,.01),spec,meteorites)
ROC1<-data.frame(sensitivity,specificity,cutoff=seq(0,1,.01)) 
ROC1%>%gather(key,rate,-cutoff)%>%ggplot(aes(cutoff,rate,color=key))+geom_path()+  geom_vline(xintercept=c(.1,.5),lty=2,color="gray50")

ROC1$TPR<-sensitivity
ROC1$FPR<-1-specificity
ROC1%>%ggplot(aes(FPR,TPR))+geom_path(size=1.5)+geom_segment(aes(x=0,y=0,xend=1,yend=1),lty=2)+  scale_x_continuous(limits = c(0,1))

library(plotROC)
ROCplot<-ggplot(meteorites)+geom_roc(aes(d=y,m=predictor), n.cuts=0) 
calc_auc(ROCplot) #AUC


class_diag<-function(probs,truth){
  
  tab<-table(factor(probs>.5,levels=c("FALSE","TRUE")),truth)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[2,2]/colSums(tab)[2]
  spec=tab[1,1]/colSums(tab)[1]
  ppv=tab[2,2]/rowSums(tab)[2]

  if(is.numeric(truth)==FALSE & is.logical(truth)==FALSE) truth<-as.numeric(truth)-1
  
  #CALCULATE EXACT AUC
  ord<-order(probs, decreasing=TRUE)
  probs <- probs[ord]; truth <- truth[ord]
  
  TPR=cumsum(truth)/max(1,sum(truth)) 
  FPR=cumsum(!truth)/max(1,sum(!truth))
  
  dup<-c(probs[-1]>=probs[-length(probs)], FALSE)
  TPR<-c(0,TPR[!dup],1); FPR<-c(0,FPR[!dup],1)
  
  n <- length(TPR)
  auc<- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )

  data.frame(acc,sens,spec,ppv,auc)
}

k=10
data1<-meteorites[sample(nrow(meteorites)),]
folds<-cut(seq(1:nrow(meteorites)),breaks=k,labels=F)

diags<-NULL 
for(i in 1:k){
  train<-data1[folds!=i,]   
  test<-data1[folds==i,]
  truth<-test$y
  fit<-glm(y~year+name_type,data=train,family="binomial")
  probs<-predict(fit,newdata = test,type="response")
  diags<-rbind(diags,class_diag(probs,truth)) 
}

apply(diags,2,mean)
```
Based on the logistic regression, the odds of being 'found' is 1.633141e-35 and the odds of being 'found' increases exponentially by 1.042 as the year increases. The odds of being a valid 'name_type' is  6.182405e-05. 

The sensitivity, or true positive rate (TPR), is 0.9946019 and the specificity, or true negative rate (TNR), is 0.2938967. This means that this model is fairly good at detecting the probability of a 'found' meteorite actually being found. However, it is not as good as detecting meteorites that 'fell'. The precision (PPV) is 0.9800011, which is the proportion of those classified as 'found' actually being found. 

The ROC curve let's us visualize trade-off between sensitivity and specificity. The AUC is 0.8979831, which means that this model is good at predicting if 'found'. The rule of thumb for AUC is 0.8-0.9 is good. After the fold classification diagnositics (I used k=500 because I had a huge dataset.), the acc (accuracy) is 0.9700408, the sens is 0.9927454, the spec is 0.2422619, and the ppv is 0.9767507. The sensitivity went down slightly and the AUC decreased as well. 

##### LASSO Regression

```{R}
fit8<-glm(y~name_type+mass+lat+long, data = meteorites, family = binomial) #While I did want to use all the rest of the variables as predictors, the dataset is so large that I limited the variables
x<-model.matrix(fit8)
y<-as.matrix(meteorites$y)
cv<-cv.glmnet(x,y,family = 'binomial')
lasso1<-glmnet(x,y,family = 'binomial',lambda=cv$lambda.1se)
coef(lasso1)

prob<-predict(lasso1, newx = x, type = "response")
class_diag(prob, meteorites$y)

k=10
meteorites$valid<-x[,"name_typeValid"]
data2<-meteorites[sample(nrow(meteorites)),]
folds2<-cut(seq(1:nrow(meteorites)),breaks=k,labels=F)

diags<-NULL 
for(i in 1:k){
  train<-data2[folds2!=i,]   
  test<-data2[folds2==i,]
  truth<-test$y
  fit<-glm(y~valid+lat+long,data=train,family="binomial")
  probs<-predict(fit,newdata = test,type="response")
  diags<-rbind(diags,class_diag(probs,truth)) 
}

apply(diags,2,mean)
summary(fit8)
```

The variables 'name_type', 'lat', and 'long' are retained. The acc ,sens, spec, and ppv are the lower when compared to the logistic regression. However, the AUC is higher when compared to the logistic regression above. The residual standard error is 6513.7. 


```{R, echo=F}
## DO NOT DELETE THIS BLOCK!
sessionInfo()
Sys.time()
Sys.info()
```